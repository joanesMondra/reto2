{
 "cells": [
  {
   "cell_type": "code",
   "id": "28432e61e6065aba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T08:43:38.596725Z",
     "start_time": "2025-01-16T08:43:38.589862Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def fft_analysis(signal):\n",
    "    slope, intercept = np.polyfit(np.arange(len(signal)), signal, 1)\n",
    "    trend = np.arange(len(signal)) * slope + intercept\n",
    "    detrended = signal - trend\n",
    "    fft_values = np.fft.fft(detrended)\n",
    "    frequencies = np.fft.fftfreq(len(fft_values))\n",
    "    # Remove negative frequencies and sort\n",
    "    positive_frequencies = frequencies[frequencies > 0]\n",
    "    magnitudes = np.abs(fft_values)[frequencies > 0]\n",
    "    # Identify dominant frequency\n",
    "    dominant_frequency = positive_frequencies[np.argmax(magnitudes)]\n",
    "    #print(f\"Dominant Frequency: {dominant_frequency:.3f}\")\n",
    "    # Convert frequency to period (e.g., days, weeks, months, etc.)\n",
    "    dominant_period = 1 / dominant_frequency\n",
    "    #print(f\"Dominant Period: {dominant_period:.2f} time units\")\n",
    "    return dominant_frequency"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-16T09:10:41.640451Z",
     "start_time": "2025-01-16T08:43:38.596725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "def process_file(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Ajustar los nombres de columnas si es necesario\n",
    "    data.columns = [\n",
    "        \"tachometer\",\n",
    "        \"acc_under_axial\",\n",
    "        \"acc_under_radiale\",\n",
    "        \"acc_under_tangencial\",\n",
    "        \"acc_over_axial\",\n",
    "        \"acc_over_radiale\",\n",
    "        \"acc_over_tangencial\",\n",
    "        \"microphone\",\n",
    "    ]\n",
    "\n",
    "    # Diccionario para estadísticas\n",
    "    statistics_dict = {}\n",
    "\n",
    "    for col in data.columns:\n",
    "        statistics_dict[f'{col}_mean'] = data[col].mean()\n",
    "        statistics_dict[f'{col}_median'] = data[col].median()\n",
    "        statistics_dict[f'{col}_std'] = data[col].std()\n",
    "        statistics_dict[f'{col}_variance'] = data[col].var()\n",
    "        statistics_dict[f'{col}_range'] = data[col].max() - data[col].min()\n",
    "        statistics_dict[f'{col}_skewness'] = data[col].skew()\n",
    "        statistics_dict[f'{col}_kurtosis'] = data[col].kurt()\n",
    "        statistics_dict[f'{col}_dominant_frequency'] = fft_analysis(data[col])\n",
    "\n",
    "    # Añadir etiqueta basada en la ruta del archivo\n",
    "    label = \"_\".join(os.path.normpath(file_path).split(os.sep)[-3:-1])  # Ajustar según la estructura\n",
    "    statistics_dict['label'] = label\n",
    "    # print(label)\n",
    "    return statistics_dict\n",
    "\n",
    "\n",
    "# Recorrer todas las carpetas y procesar los archivos\n",
    "def process_directory(root_dir):\n",
    "    all_statistics = []\n",
    "\n",
    "    for subdir, _, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                # print(f\"Procesando archivo: {file_path}\")\n",
    "                try:\n",
    "                    stats = process_file(file_path)\n",
    "                    all_statistics.append(stats)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error procesando {file_path}: {e}\")\n",
    "\n",
    "    # Combinar todos los resultados en un solo DataFrame\n",
    "    combined_df = pd.DataFrame(all_statistics)\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "# Ruta principal donde están las carpetas\n",
    "root_dir = './bearing_fault_detection'\n",
    "output_csv_path = 'combined_statistics_full.csv'\n",
    "\n",
    "# Procesar directorio y guardar resultados\n",
    "combined_df = process_directory(root_dir)\n",
    "combined_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Archivo grande combinado guardado en: {output_csv_path}\")\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo grande combinado guardado en: combined_statistics_full.csv\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
