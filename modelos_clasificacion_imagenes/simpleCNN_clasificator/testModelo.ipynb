{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-25T15:46:16.420971Z",
     "start_time": "2025-01-25T15:46:10.043826Z"
    }
   },
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T15:49:14.608113Z",
     "start_time": "2025-01-25T15:49:13.044760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# ==================================================\n",
    "# Dataset Personalizado\n",
    "# ==================================================\n",
    "class DefectDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.data = []\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        for folder in sorted(os.listdir(self.root_dir)):\n",
    "            folder_path = os.path.join(self.root_dir, folder)\n",
    "            if not os.path.isdir(folder_path):\n",
    "                continue\n",
    "\n",
    "            images = sorted([f for f in os.listdir(folder_path) if f.endswith(\".jpg\")])\n",
    "            masks = sorted([f for f in os.listdir(folder_path) if f.endswith(\"_label.bmp\")])\n",
    "\n",
    "            for img_name, mask_name in zip(images, masks):\n",
    "                img_path = os.path.join(folder_path, img_name)\n",
    "                mask_path = os.path.join(folder_path, mask_name)\n",
    "\n",
    "                mask = Image.open(mask_path).convert(\"L\")\n",
    "                mask_array = torch.tensor(list(mask.getdata())).reshape(mask.size)\n",
    "                label = 1 if mask_array.max() > 0 else 0\n",
    "                self.data.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# ==================================================\n",
    "# Modelo SimpleCNN\n",
    "# ==================================================\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(64 * 64 * 64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# ==================================================\n",
    "# Cargar el Modelo\n",
    "# ==================================================\n",
    "def load_model(model, optimizer, path=\"model.pkl\", device='cpu'):\n",
    "    if os.path.exists(path):\n",
    "        checkpoint = torch.load(path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        print(f\"Modelo cargado desde {path}\")\n",
    "    else:\n",
    "        print(f\"No se encontró el archivo {path}\")\n",
    "    return model, optimizer\n",
    "\n",
    "# ==================================================\n",
    "# Evaluación y Métricas\n",
    "# ==================================================\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device).float().view(-1, 1)\n",
    "            outputs = model(images)\n",
    "            predictions = (outputs > 0.5).float()\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Precisión total: {accuracy:.2f}%\")\n",
    "\n",
    "def evaluate_with_confusion_matrix(model, test_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device).float().view(-1, 1)\n",
    "            outputs = model(images)\n",
    "            predictions = (outputs > 0.5).float()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_predictions, labels=[0, 1])\n",
    "    plot_confusion_matrix(cm, classes=['OK', 'NOK'])\n",
    "\n",
    "def plot_confusion_matrix(cm, classes):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.ylabel('Etiqueta Real')\n",
    "    plt.title('Matriz de Confusión')\n",
    "    plt.show()\n",
    "\n",
    "def find_and_analyze_misclassified(model, test_loader, num_visualizations=10):\n",
    "    model.eval()\n",
    "    misclassified = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device).float().view(-1, 1)\n",
    "            outputs = model(images)\n",
    "            predictions = (outputs > 0.5).float()\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                if predictions[i].item() != labels[i].item():\n",
    "                    misclassified.append((images[i], labels[i].item(), predictions[i].item()))\n",
    "\n",
    "    visualize_misclassified(misclassified, num_visualizations)\n",
    "\n",
    "def visualize_misclassified(misclassified, num_visualizations):\n",
    "    for i, (image, label, prediction) in enumerate(misclassified[:num_visualizations]):\n",
    "        image = image.cpu().permute(1, 2, 0)\n",
    "        image = image * 0.5 + 0.5\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(image.numpy())\n",
    "        plt.title(f\"Etiqueta: {'OK' if label == 0 else 'NOK'} | Predicción: {'OK' if prediction == 0 else 'NOK'}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# ==================================================\n",
    "# Evaluar con Nuevos Datos\n",
    "# ==================================================\n",
    "def evaluate_with_new_data(model, new_data_dir, transform, batch_size=16):\n",
    "    new_dataset = DefectDataset(root_dir=new_data_dir, transform=transform)\n",
    "    new_loader = DataLoader(new_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_model(model, new_loader)\n",
    "    evaluate_with_confusion_matrix(model, new_loader)\n",
    "    find_and_analyze_misclassified(model, new_loader, num_visualizations=10)\n",
    "\n",
    "# ==================================================\n",
    "# Configurar Nuevos Datos\n",
    "# ==================================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "new_data_dir = \"./Imagenes_defectos3\"  # Cambia esto a tu directorio de nuevos datos\n",
    "\n",
    "# Cargar el modelo\n",
    "new_model = SimpleCNN().to(device)\n",
    "new_optimizer = torch.optim.Adam(new_model.parameters(), lr=0.001)\n",
    "new_model, new_optimizer = load_model(new_model, new_optimizer, path=\"model_resnet_con_aumento.pkl\", device=device)\n",
    "\n",
    "# Transformaciones para los nuevos datos\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "# Evaluar el modelo con nuevos datos\n",
    "evaluate_with_new_data(new_model, new_data_dir, transform=transform)\n",
    "\n"
   ],
   "id": "a96d096083ade78c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Esteb\\AppData\\Local\\Temp\\ipykernel_20552\\1752910156.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path, map_location=device)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Invalid magic number; corrupt file?",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 176\u001B[0m\n\u001B[0;32m    174\u001B[0m new_model \u001B[38;5;241m=\u001B[39m SimpleCNN()\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m    175\u001B[0m new_optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(new_model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m)\n\u001B[1;32m--> 176\u001B[0m new_model, new_optimizer \u001B[38;5;241m=\u001B[39m load_model(new_model, new_optimizer, path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_resnet_con_aumento.pkl\u001B[39m\u001B[38;5;124m\"\u001B[39m, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[0;32m    178\u001B[0m \u001B[38;5;66;03m# Transformaciones para los nuevos datos\u001B[39;00m\n\u001B[0;32m    179\u001B[0m transform \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[0;32m    180\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mResize((\u001B[38;5;241m256\u001B[39m, \u001B[38;5;241m256\u001B[39m)),\n\u001B[0;32m    181\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mToTensor(),\n\u001B[0;32m    182\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mNormalize(mean\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m], std\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m]),\n\u001B[0;32m    183\u001B[0m ])\n",
      "Cell \u001B[1;32mIn[3], line 82\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(model, optimizer, path, device)\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_model\u001B[39m(model, optimizer, path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel.pkl\u001B[39m\u001B[38;5;124m\"\u001B[39m, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m     81\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(path):\n\u001B[1;32m---> 82\u001B[0m         checkpoint \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mload(path, map_location\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[0;32m     83\u001B[0m         model\u001B[38;5;241m.\u001B[39mload_state_dict(checkpoint[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel_state_dict\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     84\u001B[0m         optimizer\u001B[38;5;241m.\u001B[39mload_state_dict(checkpoint[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moptimizer_state_dict\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[1;32m~\\.conda\\envs\\pythonProject1\\Lib\\site-packages\\torch\\serialization.py:1384\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1382\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1383\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(_get_wo_message(\u001B[38;5;28mstr\u001B[39m(e))) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1384\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _legacy_load(\n\u001B[0;32m   1385\u001B[0m     opened_file, map_location, pickle_module, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args\n\u001B[0;32m   1386\u001B[0m )\n",
      "File \u001B[1;32m~\\.conda\\envs\\pythonProject1\\Lib\\site-packages\\torch\\serialization.py:1630\u001B[0m, in \u001B[0;36m_legacy_load\u001B[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1628\u001B[0m magic_number \u001B[38;5;241m=\u001B[39m pickle_module\u001B[38;5;241m.\u001B[39mload(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m   1629\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m magic_number \u001B[38;5;241m!=\u001B[39m MAGIC_NUMBER:\n\u001B[1;32m-> 1630\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid magic number; corrupt file?\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1631\u001B[0m protocol_version \u001B[38;5;241m=\u001B[39m pickle_module\u001B[38;5;241m.\u001B[39mload(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m   1632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m protocol_version \u001B[38;5;241m!=\u001B[39m PROTOCOL_VERSION:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Invalid magic number; corrupt file?"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b561427bb1d2d375"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
